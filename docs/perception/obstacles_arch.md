# 激光雷达感知模块: LiDAR Obstacles Perception

本文档结合代码详细地解释感知模块中障碍物感知的流程与功能，也可以官方参考文档([Apollo 2.0 Obstacles Perception](https://github.com/ApolloAuto/apollo/blob/master/docs/specs/3d_obstacle_perception_cn.md)

## 硬件简介

Apollo2.0 中激光雷达感知模块使用的是Velodyne 64线激光雷达。

![img](https://github.com/YannZyl/Apollo-Note/blob/master/images/perception_obstacles/lidar_pic.png)

**Key Features:**

- 64 Channels
- 120m range
- 2.2 Million Points per Second
- 360° Horizontal FOV
- 26.9° Vertical FOV
- 0.08° angular resolution (azimuth)
- <2cm accuracy
- ~0.4° Vertical Resolution
- User selectable frame rate
- Rugged Design

![online](images/online_icon.png)Webpage for Velodyne HDL-64E S3:
[http://velodynelidar.com/hdl-64e.html](http://velodynelidar.com/hdl-64e.html)

## 功能介绍

任何时刻，激光雷达将会对汽车周围360°范围内捕获三维点云，然后对点云做后续处理。感知模块主要的工作由4块，分别为：

(1) 高精地图ROI过滤器

该过程处理在ROI之外的激光雷达点，去除背景对象，如路边建筑物和树木等，剩余的点云留待后续处理(这里的ROI区域是指汽车周围路面区域，路面外区域不用理会)。再具体的处理过程中主要步骤为：

-  数据接收与存储

接收来自激光雷达的原始点云数据，设备id，时间戳ts等信息，并将其信息存入自定义类中。

- 点云坐标系转换

原始点云参考系是Lidar坐标系，在实际处理的过程中需要考虑到方向，所以需要将点云转换到局部坐标系(Lidar ENU坐标系，也叫作东北天坐标系)

- ROI LUT构造与点查询

高精地图查询到的路面轮廓多边形，通过构造LUT，将路面轮廓多边形映射到一个二维表中。这样做目的是当给定一个新的点云坐标，就可以通过转换成二维的映射表坐标，查询以后就可以知道该点是否在路面中。

- 点云筛选

通过上一步构造完成的LUT二维映射表，可以对局部坐标系中的点云就行筛选。每个点云根据现在的坐标去计算LUT二维表格中的坐标，然后查询是否在路面多边形区域内即可。最终筛选出路面ROI区域内的点云做下一步处理。

(2) 基于卷积神经网络分割

高精地图 ROI过滤之后，Apollo得到已过滤、只包含属于ROI内的点云，大部分背景障碍物，如路侧的建筑物、树木等均被移除，ROI内的点云被传递到分割模块。分割模块检测和划分前景障碍物，例如汽车，卡车，自行车和行人。具体的处理过程包涵一下步骤：

- 通道特征提取

由(1)可以得到筛选过后的路面区域点云，然后对这个路面区域构建一个512x512的2D俯视投影网格(原本ROI内的点云是车辆70米范围内，现在投影到512个网格中)，每个网格内包含若干点云。最终对网格进行8个变量的统计，得到512x512x8的特征图、

- 基于卷积神经网络的障碍物预测

对于上述得到的1x512x512x8大小特征图进行基于神经网络的分割，输出大小为1x512x512x12，表示每个网格点是否是物体、物体偏移中心、置信度概率、物体类别等信息。

- 障碍物聚类

对于卷积神经网络输出的特征图进行障碍物聚类，聚类依据是上述的物体偏移中心，将有可能是一类的网络进行汇聚，最终得到各类的物体。

- 后期处理

在后期处理中，Apollo首先对所涉及的单元格的积极性和物体高度值，平均计算每个候选群体的检测置信度分数和物体高度。然后，Apollo去除相对于预测物体高度太高的点，并收集每个候选集中的有效单元格的点。 最后，Apollo删除具有非常低的可信度分数或小点数的候选聚类，以输出最终的障碍物集/分段。

(3) MinBox障碍物边框构建

上一步CNN分割与后期处理，可以得到lidar一定区域内的障碍物集群。接下去我们将对这些障碍物集群建立其标定框。标定框的作用除了标识物体，还有一个作用就是标记障碍物的长length，宽width，高height。其中规定长length大于宽width，障碍物方向就是长的方向direction。主要流程为

- MinBox构建--计算2DXY平面投影

在(2)中通过聚类可以得到每个类的点云集合，该步骤就是对点云进行投影到2维XY平面，然后计算点云的凸包，即多边形。

- MinBox构建--边框构建

对上述得到的多边形做一个边框构建(尽可能用一个面积小的矩阵去覆盖多边形)


(4) HM对象跟踪

该过程其实对物体进行跟踪和运动估计。主要步骤为：

- 预处理

主要做的工作是将原始点云从lidar坐标系转换到局部坐标系。然后开始是将(3)中检测到的物体加入跟踪列表

- 卡尔曼滤波，跟踪物体对象(卡尔曼滤波阶段1： Predict)

对上面已在跟踪列表中的物体进行运动估计，估计出当前时刻的位置与速度。

- 匈牙利算法比配，关联检测物体和跟踪物体

对已在跟踪列表中的物体和当前时刻CNN检测到的物体做关联匹配。例如跟踪列表中A物体对应当前时刻CNN检测到的B物体，跟踪列表中B物体找不到CNN检测到的物体与之对应等等。

- 卡尔曼滤波，更新跟踪物体位置与速度信息(卡尔曼滤波阶段2：Update阶段)

若已跟踪物体--CNN检测新物体匹配成功，则使用卡尔曼滤波更新当前物体的最优位置；如果跟踪列表物体失配，超时可以移出跟踪列表；如果新物体失配，则加入跟踪列表。